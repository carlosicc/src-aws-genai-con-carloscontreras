{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples source: [LangChain Docs](https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify here your MODEL; \n",
    "# - e.g. anthropic.claude-3-5-sonnet-20240620-v1:0, meta.llama3-8b-instruct-v1:0, anthropic.claude-3-5-haiku-20241022-v1:0\n",
    "MODEL_ID=\"meta.llama3-8b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de in-memory Vector Store usando URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# Embeddings Model\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "titan_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",\n",
    "                                     client=bedrock)\n",
    "\n",
    "# Store splits\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=titan_embeddings)\n",
    "\n",
    "# LLM\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL_ID,\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL: Query Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt\n",
    "prompt = PromptTemplate.from_template(\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RunnablePassthrough: pass directly the user question, without modification\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vectorstore.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = qa_chain.invoke(\"What are autonomous agents?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Cómo usar el CSVLoader de LangChain\n",
    "> Mas info en: [LangChain Docs](https://python.langchain.com/docs/integrations/document_loaders/csv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"./data/ecomm_sample_etl_output/Mixed_data_Arts_Dolls_Surveillance.csv\",\n",
    "                   source_column=\"subcategory_1\",\n",
    "                   csv_args={\n",
    "                       \"delimiter\": \",\"\n",
    "                       },)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea FAISS Vector Store con los docs de eComm, usando CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Load from local data\n",
    "loader = CSVLoader(file_path=\"./data/ecomm_sample_etl_output/Mixed_data_Arts_Dolls_Surveillance.csv\",\n",
    "                   source_column=\"subcategory_1\",\n",
    "                   csv_args={\n",
    "                       \"delimiter\": \",\"\n",
    "                       },)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "# Do we need chunking?\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# Embeddings Model\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "titan_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",\n",
    "                                     client=bedrock)\n",
    "\n",
    "# Store splits\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=titan_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL_ID,\n",
    "    model_kwargs=dict(temperature=0,\n",
    "                      max_tokens=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a pausar rápido, para ver el chunking interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Load from local data\n",
    "loader = CSVLoader(file_path=\"./data/ecomm_sample_etl_output/Mixed_data_Arts_Dolls_Surveillance.csv\",\n",
    "                   source_column=\"subcategory_1\",\n",
    "                   csv_args={\n",
    "                       \"delimiter\": \",\"\n",
    "                       },)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "# Do we need chunking?\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(all_splits[0].page_content[:1000])\n",
    "pprint(all_splits[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a string parser. \n",
    "            Your task is to receive a string input in a specific format, and return it in a different format.\n",
    "            The format you must return is like the following:\n",
    "\n",
    "            === Source: Dolls ===\n",
    "\n",
    "            --- Row: 0 ---\n",
    "                product_id: a4c653055a9b0e7b5c1fa1cf68be9537\n",
    "                product_name: Barbie Doll House\n",
    "                manufacturer: Matell\n",
    "                price: 34\n",
    "                number_available_in_stock: 13\n",
    "                number_of_reviews: 3\n",
    "                average_review_rating: 3.9\n",
    "                subcategory_1: Dolls\n",
    "                subcategory_2: \n",
    "                subcategory_3: \n",
    "                subcategory_4: \n",
    "                category: Toys\n",
    "\n",
    "            === Source: Art Sand ===\n",
    "\n",
    "            --- Row: 1 ---\n",
    "                product_id: 68750ff6d9a5808ed0360e48d1204215\n",
    "                product_name: Security Fashion Hourglass 10 Minutes Sand Timer -Orange\n",
    "                manufacturer: Generic\n",
    "                price: 5.21\n",
    "                number_available_in_stock: 10\n",
    "                number_of_reviews: 8\n",
    "                average_review_rating: 5\n",
    "                subcategory_1: Art Sand\n",
    "                subcategory_2: \n",
    "                subcategory_3: \n",
    "                subcategory_4: \n",
    "                category: Arts & Crafts\n",
    "            \n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"\"\"Below you have the input, coming from a CSVLoader generated by the LangChain document loader: \n",
    "            <input>\n",
    "            {input}\n",
    "            </input>\n",
    "         \"\"\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\": all_splits,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query ecommerce data from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt\n",
    "prompt = PromptTemplate.from_template(\"\"\"You are a friendly assistant for an ecommerce store. Look for the products the customer is looking for. Ask the user if they want more details, such as reviews or price. Try upselling.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RunnablePassthrough: pass directly the user question, without modification\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vectorstore.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = qa_chain.invoke(\"Do you have dolls? If so, what's the price\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
