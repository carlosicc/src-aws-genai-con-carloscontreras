{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK & Client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-west-2')\n",
    "bedrock_client = boto3.client('bedrock', region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante: Aquí listará los inference endpoints de la región elegida; e.g. US o EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List inference endpoints\n",
    "response = bedrock_client.list_inference_profiles()\n",
    "print('\\n'.join([p['inferenceProfileArn'] for p in response['inferenceProfileSummaries']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elige tu modelo, acorde a tu región: https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html \n",
    "model_id = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Bedrock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Hola! Soy Carlos Contreras ¿Cuáles son los pros y contras de usar AWS Lambda vs una instancia EC2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.converse(\n",
    "      modelId=model_id,\n",
    "      system=[{\n",
    "        \"text\": \"Eres un experto en AWS\"\n",
    "      }],\n",
    "      messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": prompt}]\n",
    "      }],\n",
    "      inferenceConfig={\n",
    "          \"maxTokens\": 4096,\n",
    "          \"temperature\": 0.5\n",
    "      },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Variables for Each Type\n",
    "response_text = response['output']['message']['content'][0]['text']\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
